{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from config import DATASET_CONFIG, PREPROCESS_CONFIG\n",
    "from preprocess.preprocess_tools import STFT, Scaler\n",
    "import preprocess.utility as sp\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import norbert\n",
    "from train.model import Generalised_Recurrent_Model\n",
    "import librosa as lib\n",
    "import librosa.display as lib_display\n",
    "# matplotlib for graphs\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating instances for preprocessing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation object\n",
    "transform = STFT(sr=DATASET_CONFIG.SR,\n",
    "                 n_per_seg=DATASET_CONFIG.N_PER_SEG,\n",
    "                 n_overlap=DATASET_CONFIG.N_OVERLAP)\n",
    "\n",
    "# Scaler object\n",
    "scaler = Scaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading music file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_path = r\"../samples/Georgia Wonder - Siren/mixture.wav\"\n",
    "# time series data of mixture\n",
    "data, sr = sp.read(track_path, stereo=True)\n",
    "print(\"Mixture file time series data shape: \", data.shape)\n",
    "\n",
    "# plotting data\n",
    "_, axes = plot.subplots(1, figsize=(12, 10))\n",
    "plot.subplot(3, 1, 2)\n",
    "plot.title(\"Mixture\")\n",
    "lib_display.waveplot(np.ascontiguousarray(data.T, dtype=np.float32), sr=sr)\n",
    "\n",
    "data = sp.to_mono(data)\n",
    "print(\"Shape of mono mixture time series data: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short time fourier transformation of time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate STFT of time series data, shape(nbframes, nb_bins, nb_channels)\n",
    "mixture_tf = transform.stft(data.T)\n",
    "\n",
    "# get spectrogram of STFT i.e., |Xi|, shape(nbframes, nb_bins, nb_channels)\n",
    "mixture_stft = np.abs(mixture_tf)\n",
    "f, axes = plot.subplots(1, figsize=(12, 10))\n",
    "axes.set_title(\"Mixture STFT\")\n",
    "axes.pcolormesh(mixture_stft[..., 0].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking how normal scaling looks Normal Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is not an actual step its only for demonstration\n",
    "usual_normalization = lib.util.normalize(mixture_stft)\n",
    "_, axes = plot.subplots(1, figsize=(12, 10))\n",
    "axes.set_title(\"Min-Max Normalized spectrogram\")\n",
    "axes.pcolormesh(usual_normalization[..., 0].T, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling/Normalizing transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the values to 0 to 1, shape(nbframes, nb_bins, nb_channels)\n",
    "X_scaled = scaler.scale(mixture_stft)\n",
    "print(\"Scaled data shape :\", X_scaled.shape)\n",
    "print(\"Scaled data min :\", np.max(X_scaled))\n",
    "print(\"Scaled data max :\", np.max(X_scaled))\n",
    "print(\"Scaled data mean :\", np.mean(X_scaled))\n",
    "X_boundary = scaler.boundary\n",
    "_, axes = plot.subplots(1, figsize=(12, 10))\n",
    "axes.set_title(\"Scaled spectrogram\")\n",
    "axes.pcolormesh(X_scaled[..., 0].T, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing the matrix to make it in shape (nb_batch, nb_frames, nb_bins)\n",
    "X_scaled = np.transpose(X_scaled, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model and predicting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "path = r'H:\\FYP\\application/controllers/models/30_2019-04-07_11-49_Generalised_Recurrent_Model_relu_accompaniment_B16_H512_S5000_adam.pt'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dnn_model = torch.load(path, map_location='cpu')\n",
    "dnn_model.to(device)\n",
    "dnn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mixture_tensor = torch.tensor(X_scaled, dtype=torch.float32, device=device).to(device)\n",
    "    estimate = dnn_model(mixture_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the results to generate the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output tensor shape (nb_batch, nb_frames, nb_bins)\n",
    "estimate_np = estimate[0].cpu().detach().numpy()\n",
    "\n",
    "_, axes = plot.subplots(1, figsize=(12, 10))\n",
    "axes.set_title(\"Estimates generated by model\")\n",
    "axes.pcolormesh(estimate_np[...].T, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking the output to make it in stereo shape\n",
    "# and transposing it back to shape (nb_frames, nb_bins, nb_channels)\n",
    "estimate_stereo = np.stack([estimate_np, estimate_np]).transpose(1, 2, 0)\n",
    "# intensifies the signal\n",
    "estimate_stereo = estimate_stereo[..., None] ** 2\n",
    "\n",
    "# stacking the mixture stft to make it in stereo shape\n",
    "# and transposing it back to shape (nb_frames, nb_bins, nb_channels)\n",
    "mixture_tf_squeeze = np.squeeze(mixture_tf)\n",
    "mixture_tf_stereo = np.stack([mixture_tf_squeeze, mixture_tf_squeeze]).transpose(1, 2, 0)\n",
    "\n",
    "# models the estimates to stft, frequency wise.\n",
    "estimate_residual = norbert.residual(estimate_stereo, mixture_tf_stereo)\n",
    "# applying wiener filers to get the sources\n",
    "estimate_filter_results = norbert.wiener(np.copy(estimate_residual), np.copy(mixture_tf_stereo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted vocals\n",
    "_, axes = plot.subplots(1, figsize=(12, 10))\n",
    "axes.set_title(\"Estimated vocals\")\n",
    "pre_vocals_tf = np.abs(estimate_filter_results[..., 1].T[1])\n",
    "pre_vocals_scaled = scaler.scale(pre_vocals_tf, boundary=X_boundary)\n",
    "axes.pcolormesh(pre_vocals_scaled, cmap=cm.gray)\n",
    "# predicted accompaniment\n",
    "_, axes = plot.subplots(1, figsize=(12, 10))\n",
    "axes.set_title(\"Estimated accompaniment\")\n",
    "pre_acc_tf = np.abs(estimate_filter_results[..., 0].T[1])\n",
    "pre_acc_scaled = scaler.scale(pre_acc_tf, boundary=X_boundary)\n",
    "axes.pcolormesh(pre_acc_scaled, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocals_path = r\"../samples/Georgia Wonder - Siren/vocals.wav\"\n",
    "# time series data of mixture\n",
    "vocals_data, sr = sp.read(vocals_path, stereo=True)\n",
    "vocals_tf = np.abs(transform.stft(vocals_data.T))\n",
    "vocals_scaled = scaler.scale(vocals_tf, boundary=X_boundary)\n",
    "# predicted vocals\n",
    "_, axes = plot.subplots(1, figsize=(12, 10))\n",
    "axes.set_title(\"Original vocals\")\n",
    "axes.pcolormesh(vocals_scaled[..., 0].T, cmap=cm.gray)\n",
    "# plot.subplot(3, 1, 2)\n",
    "# plot.title(\"Original vocals\")\n",
    "# lib_display.waveplot(np.ascontiguousarray(vocals_data.T, dtype=np.float32), sr=sr)\n",
    "\n",
    "acc_path = r\"../samples/Georgia Wonder - Siren/accompaniment.wav\"\n",
    "# time series data of mixture\n",
    "acc_data, sr = sp.read(acc_path, stereo=True)\n",
    "acc_tf = np.abs(transform.stft(acc_data.T))\n",
    "acc_scaled = scaler.scale(acc_tf, boundary=X_boundary)\n",
    "# predicted vocals\n",
    "_, axes = plot.subplots(1, figsize=(12, 10))\n",
    "axes.set_title(\"Original accompaniment\")\n",
    "axes.pcolormesh(acc_scaled[..., 0].T, cmap=cm.gray)\n",
    "# plot.subplot(3, 1, 2)\n",
    "# plot.title(\"Original accompaniment\")\n",
    "# lib_display.waveplot(np.ascontiguousarray(vocals_data.T, dtype=np.float32), sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered estimates\n",
    "vocals_estimate = transform.istft(estimate_filter_results[..., 1]).T\n",
    "acc_estimate = transform.istft(estimate_filter_results[..., 0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(acc_estimate.T, rate=44100))\n",
    "display(Audio(vocals_estimate.T, rate=44100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "# output tensor shape (nb_batch, nb_frames, nb_bins)\n",
    "estimate_np = estimate[0].cpu().detach().numpy()\n",
    "inverted = np.subtract(1.0, estimate_np)\n",
    "print(\"estimate shape\", estimate_np[...,None].shape)\n",
    "print(\"estimate mean\", np.mean(estimate_np))\n",
    "print(\"estimate max\", np.max(estimate_np))\n",
    "print(\"estimate min\", np.min(estimate_np))\n",
    "print(mixture_tf.shape)\n",
    "acc_estimate = mixture_tf*estimate_np[..., None]\n",
    "res = transform.istft(acc_estimate).T\n",
    "display(Audio(data.T, rate=44100))\n",
    "display(Audio(res.T, rate=44100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
